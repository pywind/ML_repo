{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Propose: Regression problem, predict real-value, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note`:\n",
    "\n",
    "- m = number of training\n",
    "- $x's$ = input features\n",
    "- $y's$ = output variables\n",
    "- $(x, y)$ one training example\n",
    "- $x^{(i)}, y^{(i)}$ : $i^{th}$ example\n",
    "- $\\alpha$ : learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One variable**\n",
    "\n",
    "`Hypothesis`: $h_{\\theta}(x) = \\theta_0 + \\theta_1x$\n",
    "\n",
    "`Cost function`:\n",
    "\n",
    "$J(\\theta_1, \\theta_2) = \\frac{1}{2m}\\sum _{i=1}^m\\:\\left(h_\\theta\\left(x^{(i)}\\right)- y^{(i)}\\right)^2$\n",
    "\n",
    "Goal: minimize $J(\\theta_1, \\theta_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "Outline:\n",
    "\n",
    "- Start with some $\\theta_0, \\theta_1$ (eg. $\\theta_0 = 0, \\theta_1 = 0$)\n",
    "- Keep changing $\\theta_0, \\theta_1$ to reduce $J(\\theta_0, \\theta_1)$ to find the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm**\n",
    "\n",
    "- Repeat until convergence:\n",
    "    $\\theta_j = \\theta_j - \\alpha\\frac{\\partial }{\\partial \\theta_j}J(\\theta_0,\\theta_1)$ with j = 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correct: Simultaneous update** \n",
    "(1)\n",
    "\n",
    "- temp_0  $=\\theta_0 - \\alpha \\frac{\\partial}{\\partial \\theta_0}J(\\theta_0, \\theta_1)$\n",
    "- temp_1  $=\\theta_1 - \\alpha \\frac{\\partial}{\\partial \\theta_1}J(\\theta_0, \\theta_1)$\n",
    "- $\\theta_0$ = temp_0\n",
    "- $\\theta_1$ = temp_1\n",
    "\n",
    "As definition, $J(\\theta_0, \\theta_1)$ is a quadratic function.\n",
    "\n",
    "![J()](https://www.mathworks.com/content/dam/mathworks/videos/s/surrogate-optimization-public.mp4/jcr:content/renditions/thumb-surrogate-optimization.png)\n",
    "So finding the minimize point, we're going through the derivative.\n",
    "[`In mathematics, the derivative is a way to show rate of change. For functions that act on the real numbers, it is the slope of the tangent line at a point on a graph.`](https://simple.wikipedia.org/wiki/Derivative_(mathematics)#:~:text=In%20mathematics%2C%20the%20derivative%20is,a%20point%20on%20a%20graph.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivative of $J(\\theta_0, \\theta_1)$\n",
    "\n",
    "**Step 1**: The derivative of the sum is equal to the sum of the derivatives.\n",
    "\n",
    " $\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0, \\theta_1)=\\frac{\\partial}{\\partial\\theta_0}(\\frac{1}{2m}\\sum_{i=1}^m\\:\\left(\\theta_0 + \\theta_1x_i-y_i\\right)^2) =\\frac{1}{2m}\\sum_{i=1}^m\\:\\frac{\\partial}{\\partial \\theta_0}\\left(\\theta_0 + \\theta_1x_i-y_i\\right)^2$\n",
    "\n",
    "**Step 2**: [`Apply power rule`](https://en.wikipedia.org/wiki/Power_rule) and [`chain rule`](https://en.wikipedia.org/wiki/Chain_rule).\n",
    "We have:\n",
    "  \n",
    "$\\frac{\\partial}{\\partial \\theta_0}(\\theta_0 + \\theta_1x_i-y_i)^2=\\frac{\\partial}{\\partial \\theta_0}(\\theta_0 + \\theta_1x_i-y_i)*2(\\theta_0 + \\theta_1x_i-y_i)^{2-1}$\n",
    "\n",
    "$=2(\\theta_0 + \\theta_1x_i-y_i)$\n",
    "\n",
    "**Step 3**:\n",
    "Totally, $\\frac{\\partial}{\\partial\\theta_0}J(\\theta_0, \\theta_1)=\\frac{1}{m}\\sum_{i=1}^m\\:\\left(\\theta_0+\\theta_1x_i-y_i\\right)$\n",
    "\n",
    "Similar to $\\theta_0$, $\\frac{\\partial}{\\partial \\theta_1}J(\\theta_0, \\theta_1)=\\frac{1}{m}\\sum_{i=1}^m\\:x_i(\\theta_0 + \\theta_1x_i-y_i)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent algorithm\n",
    "\n",
    "Above we have the derivative which is the decrease of the function J.\n",
    "If want to control the reduce of theta, we have the learning rate. Set that to 0.0000001 -> 0.001 would be reasonable for a good accuracy.\n",
    "\n",
    "Repeat until convergence (`with amount iteration`) {\n",
    "\n",
    "- temp_0  $=\\theta_0-\\alpha \\frac{1}{m}\\sum_{i=1}^m\\:(\\theta_0 + \\theta_1x_i-y_i)$\n",
    "- temp_1  $=\\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^m\\:x_i(\\theta_0 + \\theta_1x_i-y_i)$\n",
    "- $\\theta_0$ = temp_0\n",
    "- $\\theta_1$ = temp_1\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Source code with python**\n",
    "\n",
    "**Import library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import data**\n",
    "\n",
    "``` python\n",
    "dat = pd.read_csv('name_file')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis and visualize before training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using seaborn or matplotlib to visualize for an overview of the data set. `In seaborn, can use jointplot or pairplot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = data[0].count()\n",
    "theta = np.zeros(2) # [0.0, 0.0]\n",
    "X = data[0] # training examples\n",
    "y = data[1] # real-values\n",
    "iters = 1500 # Depending size of data\n",
    "alpha = 0.0001 # Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to monitor the convergence by computing the cost.\n",
    "def cost_function(X, y, theta):\n",
    "    # set theta0 = 0, theta1 = 0\n",
    "    total_error = 0\n",
    "    for i in range(len(X)):\n",
    "        total_error += ((theta[0] + theta[1]*X[i]) - y[i])**2\n",
    "    return total_error / (2 * len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientDescent(X, y, theta, learning_rate):\n",
    "    temp_0, temp_1 = 0, 0 # to update simultaneously\n",
    "    m = float(len(X))\n",
    "    for i in range(len(X)):\n",
    "        temp_0 +=  (theta[0] + theta[1]*X[i] - y[i])\n",
    "        temp_1 +=  X[i]*(theta[0] + theta[1]*X[i] - y[i])\n",
    "\n",
    "    theta[0] = theta[0] - learning_rate*temp_0 / m\n",
    "    theta[1] = theta[1] - learning_rate*temp_1 / m\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, y, theta, learning_rate, iters):\n",
    "    for i in range(iters):\n",
    "        theta = GradientDescent(X, y, theta, learning_rate)\n",
    "    return theta\n",
    "\n",
    "# The result of theta\n",
    "theta = training(X, y, theta, alpha, iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Đoạn này mình viết bằng tiếng việt sợ còn chưa hiểu nói gì ENG :v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đạo hàm của hàm nhiều biến\n",
    "$f(x_1, x_2, ..., x_n)$\n",
    "\n",
    "Cụ thể, cho hàm số $f(x, y)$ và một điểm $M(x_0, y_0)$ thuộc tập xác định của hàm, khi đó đạo hàm theo biến $x$ tại điểm M được gọi là đạo hàm riêng của $f$ theo $x$ tại M. Lúc này $y$ sẽ được cố định bằng giá trị $y_0$ và hàm của ta có thể coi là hàm 1 biến của biến $x$.\n",
    "\n",
    "Định nghĩa:\n",
    "$f_x^{\\prime}(x_0, y_0) = \\lim\\limits_{\\triangle_x \\rightarrow 0} \\frac{\\triangle_xf}{\\triangle_x} = \\lim\\limits_{\\triangle_x \\rightarrow 0} \\frac{f(x_0 + \\triangle_x, y_0) - f(x_0, y_0)}{\\triangle_x}$\n",
    "\n",
    "Với đạo hàm theo như đạo hàm riêng của x\n",
    "\n",
    "`Công thức đạo hàm riêng của hàm hợp` theo *chain rule*\n",
    "\n",
    "$F(u,v) = u(x,y)+v(x,y)$\n",
    "\n",
    "$\\left\\{\\begin{matrix}\n",
    "\\frac{\\partial F}{\\partial x} = \\frac{\\partial F}{\\partial u}\\frac{\\partial u}{\\partial x}\\\\ \\frac{\\partial F}{\\partial y} = \\frac{\\partial F}{\\partial v}\\frac{\\partial v}{\\partial y}\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "* Ma trận Jacobi của phép đổi biến $u=u(x,y), v=v(x, y)$\n",
    "\n",
    "$J=\\begin{pmatrix}\\frac{\\partial u}{\\partial x}&\\frac{\\partial v}{\\partial x}\\\\ \\frac{\\partial v}{\\partial y}&\\frac{\\partial v}{\\partial y}\\end{pmatrix}$\n",
    "\n",
    "## Đạo hàm theo hướng - Gradient\n",
    "\n",
    "Bổ đề: $\\overrightarrow{l}$ là vector đơn vị.\n",
    "\n",
    "Nếu ta kết hợp các đạo hàm riêng lại thành một véc-tơ và tính đạo hàm teo véc-tơ đó thì ta sẽ thu được đạo hàm toàn phần. Hay nói cách khác là đạo hàm theo tất cả các biến hay đạo hàm theo véc-tơ hợp thành đó. Đạo hàm này được gọi là gradient của hàm theo véc-tơ tương ứng.\n",
    "\n",
    "Ta có gradient tại điểm M:\n",
    "\n",
    "$\\nabla{f(x_0, y_0)} = \\Bigg(\\frac{\\partial{f}}{\\partial{x}}(x_0, y_0), \\frac{\\partial{f}}{\\partial{y}}(x_0, y_0)\\Bigg)$\n",
    "\n",
    "Gradient là **một vector cột**, kí hiệu $\\nabla{f}=\\left[\\frac{\\partial f}{\\partial x} \\right]\\overrightarrow{i} + \\left[\\frac{\\partial f}{\\partial y} \\right]\\overrightarrow{j}$\n",
    "\n",
    "Ví dụ, hàm số $f(x, y) = x^2 + y^2$\n",
    "  sẽ có gradient là: $\\nabla{f} = \\begin{bmatrix} 2x \\cr 2y \\end{bmatrix}$\n",
    "\n",
    "Đối với hàm véc-tơ, nhớ lại rằng đạo hàm riêng của nó là một véc-tơ hàng mà gradient thành kết hợp theo véc-tơ cột, nên gradient của hàm véc-tơ sẽ là một ma trận có số hàng bằng với số chiều véc-tơ giá trị và số cột bằng với số biến.\n",
    "\n",
    "$J = \\nabla f = \\begin{bmatrix}\n",
    " \\nabla f_1& \\cdots &\\nabla f_n \\end{bmatrix}=\\begin{pmatrix}\n",
    "\\frac{\\partial{f_1}}{\\partial{x_1}} &\\cdots & \\frac{\\partial{f_n}}{\\partial{x_1}}\\\\ \\vdots  & \\ddots & \\vdots \\\\ \\frac{\\partial{f_n}}{\\partial{x_1}} &\\cdots &\\frac{\\partial{f_n}}{\\partial{x_n}} \\end{pmatrix}$\n",
    "\n",
    " Ta có thể thấy rằng chiều của gradient sẽ cùng chiều với véc-tơ lấy đạo hàm. Hay nói một cách khác, hàm số tăng nhanh nhất theo hướng của gradient và giảm nhanh nhất khi ngược hướng với gradient của nó.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
